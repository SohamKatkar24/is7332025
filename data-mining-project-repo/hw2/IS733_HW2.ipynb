{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1db41b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\soham\\anaconda3\\Lib\\site-packages\\ydata_profiling\\profile_report.py:358: UserWarning: Try running command: 'pip install --upgrade Pillow' to avoid ValueError\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dde93fc0a1084428a7b791260ba4b973",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaac08ad1d384fb8bc22eb9fd3c78fac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dde46c0206d47d9a58b6f4f6518f6fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Render HTML:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c19075b3f8fd46f29b81f0ae7efd0434",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Export report to file:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          AUC  Accuracy\n",
      "Baseline             0.500000  0.528887\n",
      "Logistic Regression  0.875819  0.784392\n",
      "Naive Bayes          0.893291  0.824773\n",
      "Decision Tree        0.816579  0.808923\n",
      "SVM-Linear           0.875446  0.793134\n",
      "SVM-RBF              0.854900  0.535844\n",
      "Random Forest        0.921983  0.847399\n",
      "Best model: Random Forest, AUC on white wine: 0.9734811957569914\n",
      "Preferred models for interpretability: ['Logistic Regression', 'Decision Tree']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\soham\\AppData\\Local\\Temp\\ipykernel_28580\\1341687790.py:83: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from pandas_profiling import ProfileReport\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "# Set Matplotlib backend to avoid display issues\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "# Load datasets\n",
    "red_wine = pd.read_csv(r\"D:\\Documents\\Sem_3\\IS733\\HW2\\red_wine.csv\")\n",
    "white_wine = pd.read_csv(r\"D:\\Documents\\Sem_3\\IS733\\HW2\\white_wine.csv\")\n",
    "\n",
    "# Generate profiling report\n",
    "profile = ProfileReport(red_wine, explorative=True)\n",
    "profile.to_file(\"red_wine_profile.html\")\n",
    "\n",
    "# Convert categorical target to binary values\n",
    "def encode_target(df):\n",
    "    df['type'] = df['type'].map({'low': 0, 'high': 1})\n",
    "    return df\n",
    "\n",
    "red_wine = encode_target(red_wine)\n",
    "white_wine = encode_target(white_wine)\n",
    "\n",
    "# Define features and target\n",
    "X_red = red_wine.drop(columns=['type'])\n",
    "y_red = red_wine['type']\n",
    "X_white = white_wine.drop(columns=['type'])\n",
    "y_white = white_wine['type']\n",
    "\n",
    "# Split data for ROC curve visualization\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_red, y_red, test_size=0.2, random_state=42, stratify=y_red)\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    \"Baseline\": DummyClassifier(strategy='most_frequent'),\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"SVM-Linear\": SVC(kernel='linear', probability=True),\n",
    "    \"SVM-RBF\": SVC(kernel='rbf', probability=True),\n",
    "    \"Random Forest\": RandomForestClassifier()\n",
    "}\n",
    "\n",
    "# SubTask 2: Perform 10-fold cross-validation\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "performance_metrics = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    auc_scores = cross_val_score(model, X_red, y_red, cv=cv, scoring='roc_auc')\n",
    "    acc_scores = cross_val_score(model, X_red, y_red, cv=cv, scoring='accuracy')\n",
    "    performance_metrics[name] = {\n",
    "        \"AUC\": np.mean(auc_scores),\n",
    "        \"Accuracy\": np.mean(acc_scores)\n",
    "    }\n",
    "\n",
    "# Convert to DataFrame for easy viewing\n",
    "performance_df = pd.DataFrame(performance_metrics).T\n",
    "print(performance_df)\n",
    "\n",
    "# SubTask 3: Train and plot ROC curve for Random Forest\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_prob_rf = rf_model.predict_proba(X_test)[:, 1]\n",
    "fpr, tpr, _ = roc_curve(y_test, y_prob_rf)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label=\"Random Forest (AUC = %.2f)\" % roc_auc_score(y_test, y_prob_rf))\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.legend()\n",
    "plt.savefig(\"roc_curve.png\")\n",
    "\n",
    "# SubTask 4: Find best model based on AUC and test on white wine\n",
    "best_model_name = max(performance_metrics, key=lambda k: performance_metrics[k][\"AUC\"])\n",
    "best_model = models[best_model_name]\n",
    "best_model.fit(X_red, y_red)\n",
    "y_white_pred = best_model.predict_proba(X_white)[:, 1]\n",
    "auc_white = roc_auc_score(y_white, y_white_pred)\n",
    "print(f\"Best model: {best_model_name}, AUC on white wine: {auc_white}\")\n",
    "\n",
    "# SubTask 5: Choosing an interpretable model\n",
    "interpretable_models = [\"Logistic Regression\", \"Decision Tree\"]\n",
    "print(f\"Preferred models for interpretability: {interpretable_models}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32ba3af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
